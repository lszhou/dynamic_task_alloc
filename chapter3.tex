%--------------------CHAPTER 3-----------------------------
\chapter{Data Structure and Implementation}

% Some questions need to be answered?
% (1) In this thesis, what is the shared memory system Architecture, CC or DSM. (Pareek_MSc_15, Wojciech_201011_PhD_thesis_17)
% (2) What is shared memory object? and what is "the implementation" of a shared memory object?
% (3) Should the random(s), etc be assumed linearizable or atomic? what's the difference here? (Pareek_MSc_20)
% The classification of memory accesses into local and remote depends on the memory
% model of the multiprocessor: In the distributed shared memory (DSM) model, a variable’s
% physical address determines locality with respect to a processor, each variable being local
% to exactly one processor and remote to all others. In the cache-coherent (CC) model,
% processors operate on cached copies of shared variables, and it is the state of a processor’s
% local cache combined with the action of the coherence protocol (which keeps consistent
% copies of a variable in different caches) that determines locality. A memory access is
% local if it results in a cache hit and can be resolved without accessing main memory or
% a remote cache; a memory access is remote otherwise. To analyze the worst-case RMR
% complexity of an algorithm, we assume that each process runs on a distinct processor.
% (For this reason, we speak of processes and processors interchangeably.)


\section{Data Structure}
The main data structure we are using for dynamic task allocation is a binary tree with unbounded number of leaves,
where each leaf is either empty or associated with a task that is available to perform during the execution.

Each tree node contains a CAS object whose state a pair of \emph{counts}, denoted as $(x, y)$.
The first count $x$ is called the \emph{insert count}, which tracks the number of tasks successfully inserted in
the subtree. The second count $y$ is called the \emph{perform count}, which tracks the number of tasks successfully
performed in the subtree.

From chapter 2, we say a task $\ell$ is inserted in the subtree and available to perform if a process has completed
\texttt{InsertTask(}$\ell$\texttt{)} call and the location $M$ is returned, but task $\ell$ has not been performed yet, and
a task $\ell$ is said to be \emph{performed} by a process if the process has completed a \texttt{DoTask()} call
which returns the task identifier $\ell$. Thus, for the CAS object $(x, y)$ of node $v$ in the tree,
the count $x$ counts the total number of successful \texttt{InsertTask} operations
executed in the subtree rooted at $v$, and  the count $y$ counts the total number of successful \texttt{DoTask} operations
executed in the subtree rooted at $v$.

%modify the definition of \emph{space}

For each node $v$, We call the difference $u = (x - y)$ the \emph{surplus} and denote it by $u_v$ and define the value $2^h - u_v$
the \emph{space} at node $v$, where $h$ is the height of node $v$. If a process reads the state
if CAS object of node $v$ as $(x ,y)$, then the surplus $u$ is the number of available tasks left in the subtree rooted at $v$,
since the there have been $x$ tasks inserted and $y$ tasks performed and the space $2^h - u_v$ is the number of tasks that can still be
inserted in the subtree rooted at node $v$.

% add initial configuration of the binary tree

\section{The Implementation of Type DTA}

The implementation for the \texttt{DoTask} operation is given in Figure 3.1.

\begin{figure}[h]
\begin{algorithm}[H]
\caption{\texttt{DoTask()}}
\While {$true$}{
   $v \leftarrow root$;\\

   \If{$v.surplus() \leq 0$}{
   \Return $\perp$;\
   }
   \BlankLine
   /* Descent */\;
    \While{$v$ is not a leaf}{
        $(x_L, y_L) \leftarrow v.left.read()$\;
        $(x_R, y_R) \leftarrow v.right.read()$\;
        $s_L \leftarrow min(x_L-y_L, 2^{height(v)})$\;
        $s_R \leftarrow min(x_R-y_R, 2^{height(v)})$\;
        $r \leftarrow random(0,1)$\;

        \uIf{$(s_L+s_R)=0$}{
            Mark-up($v$)\;
        }
        \uElseIf{$r<s_L/(s_L+s_R)$}{
            $v \leftarrow v.left$\;
        }
        \Else{
            $v \leftarrow v.rght$\;
        }
    }

    \BlankLine
    /* $v$ is a leaf */\;
    $(x,y) \leftarrow v.read()$\;
    $(flag, l)$ $\leftarrow$ $v$.\texttt{TryTask}(task$[y+1]$)\;

    \BlankLine
    /* Update Insertion Count */\;
    $v$.CAS$((x, y), (x, y+1))$\;
    $v \leftarrow v.parent$\;
    Mark-up($v$)\;
    \If{$flag$ = $success$}{
        \Return $\ell$
    }
}
\end{algorithm}
\caption{DoTask}
\end{figure}



\begin{figure}[h]
\begin{algorithm}[H]
\caption{\texttt{InsertTask(}$\ell$\texttt{)}}
\While{$true$}{
    $v \leftarrow root$\;
    \BlankLine
    /* Descent */\;
    \While{$v$ is not a leaf}{
        $(x_L, y_L) \leftarrow v.left.read()$\;
        $(x_R, y_R) \leftarrow v.right.read()$\;
        $s_L \leftarrow 2^{height(v)} - min(x_L-y_L, 2^{height(v)})$\;
        $s_R \leftarrow 2^{height(v)} - min(x_R-y_R, 2^{height(v)})$\;
        $r \leftarrow random(0,1)$\;

        \uIf{$(s_L+s_R)=0$}{
            Mark-up($v$)\;
        }
        \uElseIf{$r<s_L/(s_L+s_R)$}{
            $v \leftarrow v.left$\;
        }
        \Else{
            $v \leftarrow v.rght$\;
        }
    }

    \BlankLine
    /* $v$ is a leaf */\;
    $(x,y) \leftarrow v.read()$\;
    $flag$ $\leftarrow$ $v$.\texttt{PutTask}(task$[x+1]$)\;

    \BlankLine
    /* Update Insertion Count */\;
    $v$.CAS$((x, y), (x+1, y))$\;
    $v \leftarrow v.parent$\;
    Mark-up($v$)\;
    \If{$flag$ = $success$}{
        \Return $success$
    }
}
\end{algorithm}
\caption{InsertTask}


\begin{algorithm}[H]
\caption{\texttt{Mark-up}($v$)}
\If{$v$ is not $null$}{
    \For {($i=0; i<2; i++$)}{
        $(x, y) \leftarrow v.read()$\;
        $(x_L, y_L) \leftarrow v.left.read()$\;
        $(x_R, y_R) \leftarrow v.right.read()$\;
        $v$.CAS$((x,y), (max(x, x_L + x_R), max(y, y_L + y_R))$\;
    }
}
\end{algorithm}
\caption{MarkUp}
\end{figure}
